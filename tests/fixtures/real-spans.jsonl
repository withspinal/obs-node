{"name":"openai-api-call","trace_id":"f5b8abd666e2dd5c90ad4007d46de644","span_id":"23871d783d0a13ee","parent_span_id":null,"start_time":[1755130071,471000000],"end_time":[1755130073,260907250],"status":{"code":1},"attributes":{"spinal.model":"openai:gpt-4o-mini-2024-07-18","spinal.input_tokens":12,"spinal.output_tokens":2,"spinal.total_tokens":14,"spinal.response.binary_data":"{\n  \"id\": \"chatcmpl-test-1\",\n  \"object\": \"chat.completion\",\n  \"created\": 1755130071,\n  \"model\": \"gpt-4o-mini-2024-07-18\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Hello!\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 12,\n    \"completion_tokens\": 2,\n    \"total_tokens\": 14\n  }\n}","spinal.response.size":812,"spinal.response.capture_method":"fetch_clone"},"events":[],"links":[],"instrumentation_info":{"name":"spinal-openai"}}
{"name":"openai-api-call","trace_id":"test-trace-1","span_id":"span-1","parent_span_id":null,"start_time":[1755129541571,0],"end_time":[1755129551571,0],"status":{"code":1},"attributes":{"spinal.model":"openai:gpt-4o-mini","spinal.input_tokens":50,"spinal.output_tokens":25,"spinal.total_tokens":75,"spinal.aggregation_id":"test-feature","spinal.response.binary_data":"{\n  \"id\": \"chatcmpl-test-2\",\n  \"object\": \"chat.completion\",\n  \"created\": 1755129541571,\n  \"model\": \"gpt-4o-mini\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"This is a test response with 25 tokens.\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 50,\n    \"completion_tokens\": 25,\n    \"total_tokens\": 75\n  }\n}","spinal.response.size":1024,"spinal.response.capture_method":"fetch_clone"},"events":[],"links":[],"instrumentation_info":{"name":"spinal-openai","version":"1.0.0"}}
{"name":"openai-api-call","trace_id":"test-trace-2","span_id":"span-2","parent_span_id":null,"start_time":[1755129571571,0],"end_time":[1755129581571,0],"status":{"code":1},"attributes":{"spinal.model":"openai:gpt-4o","spinal.input_tokens":100,"spinal.output_tokens":50,"spinal.total_tokens":150,"spinal.aggregation_id":"test-feature","spinal.response.binary_data":"{\n  \"id\": \"chatcmpl-test-3\",\n  \"object\": \"chat.completion\",\n  \"created\": 1755129571571,\n  \"model\": \"gpt-4o\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"This is a longer test response with 50 tokens for the gpt-4o model.\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 100,\n    \"completion_tokens\": 50,\n    \"total_tokens\": 150\n  }\n}","spinal.response.size":1456,"spinal.response.capture_method":"fetch_clone"},"events":[],"links":[],"instrumentation_info":{"name":"spinal-openai","version":"1.0.0"}}
{"name":"openai-api-call","trace_id":"test-trace-3","span_id":"span-3","parent_span_id":null,"start_time":[1755129601571,0],"end_time":[1755129611571,0],"status":{"code":2},"attributes":{"spinal.model":"openai:gpt-4o-mini","spinal.input_tokens":30,"spinal.output_tokens":0,"spinal.total_tokens":30,"spinal.aggregation_id":"error-test","spinal.response.binary_data":"{\n  \"error\": {\n    \"message\": \"Rate limit exceeded\",\n    \"type\": \"rate_limit_exceeded\",\n    \"code\": \"rate_limit_exceeded\"\n  }\n}","spinal.response.size":156,"spinal.response.capture_method":"fetch_clone"},"events":[],"links":[],"instrumentation_info":{"name":"spinal-openai","version":"1.0.0"}}
{"name":"openai-api-call","trace_id":"test-trace-4","span_id":"span-4","parent_span_id":null,"start_time":[1755129631571,0],"end_time":[1755129641571,0],"status":{"code":1},"attributes":{"spinal.model":"openai:gpt-4o","spinal.input_tokens":200,"spinal.output_tokens":100,"spinal.total_tokens":300,"spinal.aggregation_id":"feature-b","spinal.response.binary_data":"{\n  \"id\": \"chatcmpl-test-5\",\n  \"object\": \"chat.completion\",\n  \"created\": 1755129631571,\n  \"model\": \"gpt-4o\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"This is a very long test response with 100 tokens for the gpt-4o model. It contains detailed information and demonstrates the full capabilities of the response data capture feature.\",\n        \"refusal\": null,\n        \"annotations\": []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 200,\n    \"completion_tokens\": 100,\n    \"total_tokens\": 300\n  }\n}","spinal.response.size":1892,"spinal.response.capture_method":"fetch_clone"},"events":[],"links":[],"instrumentation_info":{"name":"spinal-openai","version":"1.0.0"}}
